[//]: # (<div align="left"><img src="docs/images/funasr_logo.jpg" width="400"/></div>)

(ç®€ä½“ä¸­æ–‡|[English](./README.md))

# FunASR: A Fundamental End-to-End Speech Recognition Toolkit
<p align="left">
    <a href=""><img src="https://img.shields.io/badge/OS-Linux%2C%20Win%2C%20Mac-brightgreen.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/Python->=3.7,<=3.10-aff.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/Pytorch-%3E%3D1.11-blue"></a>
</p>

FunASRå¸Œæœ›åœ¨è¯­éŸ³è¯†åˆ«çš„å­¦æœ¯ç ”ç©¶å’Œå·¥ä¸šåº”ç”¨ä¹‹é—´æ¶èµ·ä¸€åº§æ¡¥æ¢ã€‚é€šè¿‡å‘å¸ƒå·¥ä¸šçº§è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒå’Œå¾®è°ƒï¼Œç ”ç©¶äººå‘˜å’Œå¼€å‘äººå‘˜å¯ä»¥æ›´æ–¹ä¾¿åœ°è¿›è¡Œè¯­éŸ³è¯†åˆ«æ¨¡å‹çš„ç ”ç©¶å’Œç”Ÿäº§ï¼Œå¹¶æ¨åŠ¨è¯­éŸ³è¯†åˆ«ç”Ÿæ€çš„å‘å±•ã€‚è®©è¯­éŸ³è¯†åˆ«æ›´æœ‰è¶£ï¼

<div align="center">  
<h4>
 <a href="#æ ¸å¿ƒåŠŸèƒ½"> æ ¸å¿ƒåŠŸèƒ½ </a>   
ï½œ<a href="#æœ€æ–°åŠ¨æ€"> æœ€æ–°åŠ¨æ€ </a>
ï½œ<a href="#å®‰è£…æ•™ç¨‹"> å®‰è£… </a>
ï½œ<a href="#å¿«é€Ÿå¼€å§‹"> å¿«é€Ÿå¼€å§‹ </a>
ï½œ<a href="https://alibaba-damo-academy.github.io/FunASR/en/index.html"> æ•™ç¨‹æ–‡æ¡£ </a>
ï½œ<a href="#æ¨¡å‹ä»“åº“"> æ¨¡å‹ä»“åº“ </a>
ï½œ<a href="#æœåŠ¡éƒ¨ç½²"> æœåŠ¡éƒ¨ç½² </a>
ï½œ<a href="#è”ç³»æˆ‘ä»¬"> è”ç³»æˆ‘ä»¬ </a>
</h4>
</div>

<a name="æ ¸å¿ƒåŠŸèƒ½"></a>
## æ ¸å¿ƒåŠŸèƒ½
- FunASRæ˜¯ä¸€ä¸ªåŸºç¡€è¯­éŸ³è¯†åˆ«å·¥å…·åŒ…ï¼Œæä¾›å¤šç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼ˆVADï¼‰ã€æ ‡ç‚¹æ¢å¤ã€è¯­è¨€æ¨¡å‹ã€è¯´è¯äººéªŒè¯ã€è¯´è¯äººåˆ†ç¦»å’Œå¤šäººå¯¹è¯è¯­éŸ³è¯†åˆ«ç­‰ã€‚FunASRæä¾›äº†ä¾¿æ·çš„è„šæœ¬å’Œæ•™ç¨‹ï¼Œæ”¯æŒé¢„è®­ç»ƒå¥½çš„æ¨¡å‹çš„æ¨ç†ä¸å¾®è°ƒã€‚
- æˆ‘ä»¬åœ¨[ModelScope](https://www.modelscope.cn/models?page=1&tasks=auto-speech-recognition)ä¸[huggingface](https://huggingface.co/FunASR)ä¸Šå‘å¸ƒäº†å¤§é‡å¼€æºæ•°æ®é›†æˆ–è€…æµ·é‡å·¥ä¸šæ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡æˆ‘ä»¬çš„[æ¨¡å‹ä»“åº“](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/model_zoo/modelscope_models.md)äº†è§£æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ã€‚ä»£è¡¨æ€§çš„[Paraformer](https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)éè‡ªå›å½’ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«æ¨¡å‹å…·æœ‰é«˜ç²¾åº¦ã€é«˜æ•ˆç‡ã€ä¾¿æ·éƒ¨ç½²çš„ä¼˜ç‚¹ï¼Œæ”¯æŒå¿«é€Ÿæ„å»ºè¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œè¯¦ç»†ä¿¡æ¯å¯ä»¥é˜…è¯»([æœåŠ¡éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md))ã€‚

<a name="æœ€æ–°åŠ¨æ€"></a>
## æœ€æ–°åŠ¨æ€
- 2023/11/08ï¼šä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡3.0 CPUç‰ˆæœ¬å‘å¸ƒï¼Œæ–°å¢æ ‡ç‚¹å¤§æ¨¡å‹ã€Ngramè¯­è¨€æ¨¡å‹ä¸wfstçƒ­è¯ï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…([ä¸€é”®éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md#ä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡cpuç‰ˆæœ¬))
- 2023/10/17: è‹±æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡ä¸€é”®éƒ¨ç½²çš„CPUç‰ˆæœ¬å‘å¸ƒï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…([ä¸€é”®éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md#è‹±æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡cpuç‰ˆæœ¬))
- 2023/10/13: [SlideSpeech](https://slidespeech.github.io/): ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€éŸ³è§†é¢‘è¯­æ–™åº“ï¼Œä¸»è¦æ˜¯åœ¨çº¿ä¼šè®®æˆ–è€…åœ¨çº¿è¯¾ç¨‹åœºæ™¯ï¼ŒåŒ…å«äº†å¤§é‡ä¸å‘è¨€äººè®²è¯å®æ—¶åŒæ­¥çš„å¹»ç¯ç‰‡ã€‚
- 2023.10.10: [Paraformer-long-Spk](https://github.com/alibaba-damo-academy/FunASR/blob/main/egs_modelscope/asr_vad_spk/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/demo.py)æ¨¡å‹å‘å¸ƒï¼Œæ”¯æŒåœ¨é•¿è¯­éŸ³è¯†åˆ«çš„åŸºç¡€ä¸Šè·å–æ¯å¥è¯çš„è¯´è¯äººæ ‡ç­¾ã€‚
- 2023.10.07: [FunCodec](https://github.com/alibaba-damo-academy/FunCodec): FunCodecæä¾›å¼€æºæ¨¡å‹å’Œè®­ç»ƒå·¥å…·ï¼Œå¯ä»¥ç”¨äºéŸ³é¢‘ç¦»æ•£ç¼–ç ï¼Œä»¥åŠåŸºäºç¦»æ•£ç¼–ç çš„è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆç­‰ä»»åŠ¡ã€‚
- 2023.09.01: ä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡2.0 CPUç‰ˆæœ¬å‘å¸ƒï¼Œæ–°å¢ffmpegã€æ—¶é—´æˆ³ä¸çƒ­è¯æ¨¡å‹æ”¯æŒï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…([ä¸€é”®éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md#ä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡cpuç‰ˆæœ¬))
- 2023.08.07: ä¸­æ–‡å®æ—¶è¯­éŸ³å¬å†™æœåŠ¡ä¸€é”®éƒ¨ç½²çš„CPUç‰ˆæœ¬å‘å¸ƒï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…([ä¸€é”®éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md#ä¸­æ–‡å®æ—¶è¯­éŸ³å¬å†™æœåŠ¡cpuç‰ˆæœ¬))
- 2023.07.17: BATä¸€ç§ä½å»¶è¿Ÿä½å†…å­˜æ¶ˆè€—çš„RNN-Tæ¨¡å‹å‘å¸ƒï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…ï¼ˆ[BAT](egs/aishell/bat)ï¼‰
- 2023.06.26: ASRU2023 å¤šé€šé“å¤šæ–¹ä¼šè®®è½¬å½•æŒ‘æˆ˜èµ›2.0å®Œæˆç«èµ›ç»“æœå…¬å¸ƒï¼Œè¯¦ç»†ä¿¡æ¯å‚é˜…ï¼ˆ[M2MeT2.0](https://alibaba-damo-academy.github.io/FunASR/m2met2_cn/index.html)ï¼‰

<a name="å®‰è£…æ•™ç¨‹"></a>
## å®‰è£…æ•™ç¨‹
FunASRå®‰è£…æ•™ç¨‹è¯·é˜…è¯»ï¼ˆ[Installation](https://alibaba-damo-academy.github.io/FunASR/en/installation/installation.html)ï¼‰

## æ¨¡å‹ä»“åº“

FunASRå¼€æºäº†å¤§é‡åœ¨å·¥ä¸šæ•°æ®ä¸Šé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‚¨å¯ä»¥åœ¨[æ¨¡å‹è®¸å¯åè®®](./MODEL_LICENSE)ä¸‹è‡ªç”±ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹å’Œåˆ†äº«FunASRæ¨¡å‹ï¼Œä¸‹é¢åˆ—ä¸¾ä»£è¡¨æ€§çš„æ¨¡å‹ï¼Œæ›´å¤šæ¨¡å‹è¯·å‚è€ƒ[æ¨¡å‹ä»“åº“]()ã€‚

ï¼ˆæ³¨ï¼š[ğŸ¤—]()è¡¨ç¤ºHuggingfaceæ¨¡å‹ä»“åº“é“¾æ¥ï¼Œ[â­]()è¡¨ç¤ºModelScopeæ¨¡å‹ä»“åº“é“¾æ¥ï¼‰


|                                                                              æ¨¡å‹åå­—                                                                               |        ä»»åŠ¡è¯¦æƒ…        |     è®­ç»ƒæ•°æ®     | å‚æ•°é‡  |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------:|:------------:|:----:|
|     paraformer-zh <br> ([â­](https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)  [ğŸ¤—]() )     |  è¯­éŸ³è¯†åˆ«ï¼Œå¸¦æ—¶é—´æˆ³è¾“å‡ºï¼Œéå®æ—¶   |  60000å°æ—¶ï¼Œä¸­æ–‡  | 220M |
|                 paraformer-zh-spk <br> ( [â­](https://modelscope.cn/models/damo/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/summary)  [ğŸ¤—]() )                 | åˆ†è§’è‰²è¯­éŸ³è¯†åˆ«ï¼Œå¸¦æ—¶é—´æˆ³è¾“å‡ºï¼Œéå®æ—¶ |  60000å°æ—¶ï¼Œä¸­æ–‡  | 220M |
|        paraformer-zh-online <br> ( [â­](https://modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/summary) [ğŸ¤—]() )         |      è¯­éŸ³è¯†åˆ«ï¼Œå®æ—¶       |  60000å°æ—¶ï¼Œä¸­æ–‡  | 220M |
|          paraformer-en <br> ( [â­](https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-en-16k-common-vocab10020/summary) [ğŸ¤—]() )          | è¯­éŸ³è¯†åˆ«ï¼Œéå®æ—¶ |  50000å°æ—¶ï¼Œè‹±æ–‡  | 220M |
|                                                                paraformer-en-spk <br> ([â­]() [ğŸ¤—]() )                                                                |      è¯­éŸ³è¯†åˆ«ï¼Œéå®æ—¶      |  50000å°æ—¶ï¼Œè‹±æ–‡  | 220M |
|                      conformer-en <br> ( [â­](https://modelscope.cn/models/damo/speech_conformer_asr-en-16k-vocab4199-pytorch/summary) [ğŸ¤—]() )                       |      è¯­éŸ³è¯†åˆ«ï¼Œéå®æ—¶      |  50000å°æ—¶ï¼Œè‹±æ–‡  | 220M |
|                      ct-punc <br> ( [â­](https://modelscope.cn/models/damo/punc_ct-transformer_cn-en-common-vocab471067-large/summary) [ğŸ¤—]() )                       |      æ ‡ç‚¹æ¢å¤      |  100Mï¼Œä¸­æ–‡ä¸è‹±æ–‡  | 1.1G | 
|                           fsmn-vad <br> ( [â­](https://modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/summary) [ğŸ¤—]() )                           |     è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼Œå®æ—¶      | 5000å°æ—¶ï¼Œä¸­æ–‡ä¸è‹±æ–‡ | 0.4M | 
|                           fa-zh <br> ( [â­](https://modelscope.cn/models/damo/speech_timestamp_prediction-v1-16k-offline/summary) [ğŸ¤—]() )                            |   å­—çº§åˆ«æ—¶é—´æˆ³é¢„æµ‹         |  50000å°æ—¶ï¼Œä¸­æ–‡  | 38M  |


<a name="å¿«é€Ÿå¼€å§‹"></a>
## å¿«é€Ÿå¼€å§‹
FunASRæ”¯æŒæ•°ä¸‡å°æ—¶å·¥ä¸šæ•°æ®è®­ç»ƒçš„æ¨¡å‹çš„æ¨ç†å’Œå¾®è°ƒï¼Œè¯¦ç»†ä¿¡æ¯å¯ä»¥å‚é˜…ï¼ˆ[modelscope_egs](https://alibaba-damo-academy.github.io/FunASR/en/modelscope_pipeline/quick_start.html)ï¼‰ï¼›ä¹Ÿæ”¯æŒå­¦æœ¯æ ‡å‡†æ•°æ®é›†æ¨¡å‹çš„è®­ç»ƒå’Œå¾®è°ƒï¼Œè¯¦ç»†ä¿¡æ¯å¯ä»¥å‚é˜…ï¼ˆ[egs](https://alibaba-damo-academy.github.io/FunASR/en/academic_recipe/asr_recipe.html)ï¼‰ã€‚

ä¸‹é¢ä¸ºå¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ï¼Œæµ‹è¯•éŸ³é¢‘ï¼ˆ[ä¸­æ–‡](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav)ï¼Œ[è‹±æ–‡]()ï¼‰

### å¯æ‰§è¡Œå‘½ä»¤è¡Œ

```shell
funasr --model paraformer-zh asr_example_zh.wav
```

æ³¨ï¼šæ”¯æŒå•æ¡éŸ³é¢‘æ–‡ä»¶è¯†åˆ«ï¼Œä¹Ÿæ”¯æŒæ–‡ä»¶åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸ºkaldié£æ ¼wav.scpï¼š`wav_id   wav_path`

### éå®æ—¶è¯­éŸ³è¯†åˆ«
```python
from funasr import infer

p = infer(model="paraformer-zh", vad_model="fsmn-vad", punc_model="ct-punc", model_hub="ms")

res = p("asr_example_zh.wav", batch_size_token=5000)
print(res)
```
æ³¨ï¼š`model_hub`ï¼šè¡¨ç¤ºæ¨¡å‹ä»“åº“ï¼Œ`ms`ä¸ºé€‰æ‹©modelscopeä¸‹è½½ï¼Œ`hf`ä¸ºé€‰æ‹©huggingfaceä¸‹è½½ã€‚

### å®æ—¶è¯­éŸ³è¯†åˆ«
```python
from funasr import infer

p = infer(model="paraformer-zh-streaming", model_hub="ms")

chunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms
param_dict = {"cache": dict(), "is_final": False, "chunk_size": chunk_size, "encoder_chunk_look_back": 4, "decoder_chunk_look_back": 1}

import torchaudio
speech = torchaudio.load("asr_example_zh.wav")[0][0]
speech_length = speech.shape[0]

stride_size = chunk_size[1] * 960
sample_offset = 0
for sample_offset in range(0, speech_length, min(stride_size, speech_length - sample_offset)):
    param_dict["is_final"] = True if sample_offset + stride_size >= speech_length - 1 else False
    input = speech[sample_offset: sample_offset + stride_size]
    rec_result = p(input=input, param_dict=param_dict)
    print(rec_result)
```
æ³¨ï¼š`chunk_size`ä¸ºæµå¼å»¶æ—¶é…ç½®ï¼Œ`[0,10,5]`è¡¨ç¤ºä¸Šå±å®æ—¶å‡ºå­—ç²’åº¦ä¸º`10*60=600ms`ï¼Œæœªæ¥ä¿¡æ¯ä¸º`5*60=300ms`ã€‚æ¯æ¬¡æ¨ç†è¾“å…¥ä¸º`600ms`ï¼ˆé‡‡æ ·ç‚¹æ•°ä¸º`16000*0.6=960`ï¼‰ï¼Œè¾“å‡ºä¸ºå¯¹åº”æ–‡å­—ï¼Œæœ€åä¸€ä¸ªè¯­éŸ³ç‰‡æ®µè¾“å…¥éœ€è¦è®¾ç½®`is_final=True`æ¥å¼ºåˆ¶è¾“å‡ºæœ€åä¸€ä¸ªå­—ã€‚

æ›´å¤šè¯¦ç»†ç”¨æ³•ï¼ˆ[æ–°äººæ–‡æ¡£](https://alibaba-damo-academy.github.io/FunASR/en/funasr/quick_start_zh.html)ï¼‰


<a name="æœåŠ¡éƒ¨ç½²"></a>
## æœåŠ¡éƒ¨ç½²
FunASRæ”¯æŒé¢„è®­ç»ƒæˆ–è€…è¿›ä¸€æ­¥å¾®è°ƒçš„æ¨¡å‹è¿›è¡ŒæœåŠ¡éƒ¨ç½²ã€‚ç›®å‰æ”¯æŒä»¥ä¸‹å‡ ç§æœåŠ¡éƒ¨ç½²ï¼š

- ä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡ï¼ˆCPUç‰ˆæœ¬ï¼‰ï¼Œå·²å®Œæˆ
- ä¸­æ–‡æµå¼è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆCPUç‰ˆæœ¬ï¼‰ï¼Œå·²å®Œæˆ
- è‹±æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡ï¼ˆCPUç‰ˆæœ¬ï¼‰ï¼Œå·²å®Œæˆ
- ä¸­æ–‡ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡ï¼ˆGPUç‰ˆæœ¬ï¼‰ï¼Œè¿›è¡Œä¸­
- æ›´å¤šæ”¯æŒä¸­

è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚é˜…([æœåŠ¡éƒ¨ç½²æ–‡æ¡£](runtime/readme_cn.md))ã€‚


<a name="ç¤¾åŒºäº¤æµ"></a>
## è”ç³»æˆ‘ä»¬

å¦‚æœæ‚¨åœ¨ä½¿ç”¨ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥åœ¨githubé¡µé¢æIssuesã€‚æ¬¢è¿è¯­éŸ³å…´è¶£çˆ±å¥½è€…æ‰«æä»¥ä¸‹çš„é’‰é’‰ç¾¤æˆ–è€…å¾®ä¿¡ç¾¤äºŒç»´ç åŠ å…¥ç¤¾åŒºç¾¤ï¼Œè¿›è¡Œäº¤æµå’Œè®¨è®ºã€‚

|                                  é’‰é’‰ç¾¤                                  |                          å¾®ä¿¡                           |
|:---------------------------------------------------------------------:|:-----------------------------------------------------:|
| <div align="left"><img src="docs/images/dingding.jpg" width="250"/>   | <img src="docs/images/wechat.png" width="215"/></div> |

## ç¤¾åŒºè´¡çŒ®è€…

| <div align="left"><img src="docs/images/alibaba.png" width="260"/> | <div align="left"><img src="docs/images/nwpu.png" width="260"/> | <img src="docs/images/China_Telecom.png" width="200"/> </div>  | <img src="docs/images/RapidAI.png" width="200"/> </div> | <img src="docs/images/aihealthx.png" width="200"/> </div> | <img src="docs/images/XVERSE.png" width="250"/> </div> |
|:------------------------------------------------------------------:|:---------------------------------------------------------------:|:--------------------------------------------------------------:|:-------------------------------------------------------:|:-----------------------------------------------------------:|:------------------------------------------------------:|

è´¡çŒ®è€…åå•è¯·å‚è€ƒï¼ˆ[è‡´è°¢åå•](./Acknowledge.md)ï¼‰


## è®¸å¯åè®®
é¡¹ç›®éµå¾ª[The MIT License](https://opensource.org/licenses/MIT)å¼€æºåè®®ï¼Œæ¨¡å‹è®¸å¯åè®®è¯·å‚è€ƒï¼ˆ[æ¨¡å‹åè®®](./MODEL_LICENSE)ï¼‰


## è®ºæ–‡å¼•ç”¨

``` bibtex
@inproceedings{gao2023funasr,
  author={Zhifu Gao and Zerui Li and Jiaming Wang and Haoneng Luo and Xian Shi and Mengzhe Chen and Yabin Li and Lingyun Zuo and Zhihao Du and Zhangyu Xiao and Shiliang Zhang},
  title={FunASR: A Fundamental End-to-End Speech Recognition Toolkit},
  year={2023},
  booktitle={INTERSPEECH},
}
@inproceedings{An2023bat,
  author={Keyu An and Xian Shi and Shiliang Zhang},
  title={BAT: Boundary aware transducer for memory-efficient and low-latency ASR},
  year={2023},
  booktitle={INTERSPEECH},
}
@inproceedings{gao22b_interspeech,
  author={Zhifu Gao and ShiLiang Zhang and Ian McLoughlin and Zhijie Yan},
  title={{Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2063--2067},
  doi={10.21437/Interspeech.2022-9996}
}
```
