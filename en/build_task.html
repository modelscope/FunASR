<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Build custom tasks &mdash; FunASR  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Export models" href="runtime/export.html" />
    <link rel="prev" title="Speaker Diarization" href="modescope_pipeline/sd_pipeline.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            FunASR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Academic Recipe</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="recipe/asr_recipe.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipe/punc_recipe.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipe/vad_recipe.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipe/sv_recipe.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipe/sd_recipe.html">Speaker Diarization</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modelscope_models.html">Pretrained Models on ModelScope</a></li>
<li class="toctree-l1"><a class="reference internal" href="huggingface_models.html">Pretrained Models on Huggingface</a></li>
</ul>
<p class="caption"><span class="caption-text">ModelScope pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/asr_pipeline.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/vad_pipeline.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/punc_pipeline.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/tp_pipeline.html">Timestamp Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/sv_pipeline.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="modescope_pipeline/sd_pipeline.html">Speaker Diarization</a></li>
</ul>
<p class="caption"><span class="caption-text">funasr library</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Build custom tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Runtime and Service</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime/export.html">Export models</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/onnxruntime_python.html">ONNXRuntime-python</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/onnxruntime_cpp.html">ONNXRuntime-cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/libtorch_python.html">Libtorch-python</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/grpc_python.html">Using funasr with grpc-python</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/grpc_cpp.html">Using funasr with grpc-cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime/websocket_python.html">Using funasr with websocket</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmark and Leadboard</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark/benchmark_onnx.html">CPU Benchmark (ONNX)</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark/benchmark_libtorch.html">CPU Benchmark (Libtorch)</a></li>
</ul>
<p class="caption"><span class="caption-text">Papers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="papers.html">Papers</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="application.html">Audio Cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="application.html#realtime-speech-recognition">Realtime Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="application.html#audio-chat">Audio Chat</a></li>
</ul>
<p class="caption"><span class="caption-text">FQA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="FQA.html">FQA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">FunASR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Build custom tasks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/build_task.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="build-custom-tasks">
<h1>Build custom tasks<a class="headerlink" href="#build-custom-tasks" title="Permalink to this headline"></a></h1>
<p>FunASR is similar to ESPNet, which applies <code class="docutils literal notranslate"><span class="pre">Task</span></code>  as the general interface ti achieve the training and inference of models. Each <code class="docutils literal notranslate"><span class="pre">Task</span></code> is a class inherited from <code class="docutils literal notranslate"><span class="pre">AbsTask</span></code> and its corresponding code can be seen in <code class="docutils literal notranslate"><span class="pre">funasr/tasks/abs_task.py</span></code>. The main functions of <code class="docutils literal notranslate"><span class="pre">AbsTask</span></code> are shown as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">AbsTask</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">add_task_arguments</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">):</span>
        <span class="k">pass</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_preprocess_fn</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
        <span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_collate_fn</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">):</span>
        <span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>add_task_arguments：Add parameters required by a specified <code class="docutils literal notranslate"><span class="pre">Task</span></code></p></li>
<li><p>build_preprocess_fn：定义如何处理对样本进行预处理 define how to preprocess samples</p></li>
<li><p>build_collate_fn：define how to combine multiple samples into a <code class="docutils literal notranslate"><span class="pre">batch</span></code></p></li>
<li><p>build_model：define the model</p></li>
<li><p>main：training interface, starting training through <code class="docutils literal notranslate"><span class="pre">Task.main()</span></code></p></li>
</ul>
<p>Next, we take the speech recognition as an example to introduce how to define a new <code class="docutils literal notranslate"><span class="pre">Task</span></code>. For the corresponding code, please see <code class="docutils literal notranslate"><span class="pre">ASRTask</span></code> in <code class="docutils literal notranslate"><span class="pre">funasr/tasks/asr.py</span></code>. The procedure of defining a new <code class="docutils literal notranslate"><span class="pre">Task</span></code> is actually the procedure of redefining the above functions according to the requirements of the specified <code class="docutils literal notranslate"><span class="pre">Task</span></code>.</p>
<ul class="simple">
<li><p>add_task_arguments</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">add_task_arguments</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Task related&quot;</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--token_list&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">str_or_none</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;A text mapping int-id to token&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>For speech recognition tasks, specific parameters required include <code class="docutils literal notranslate"><span class="pre">token_list</span></code>, etc. According to the specific requirements of different tasks, users can define corresponding parameters in this function.</p>
<ul class="simple">
<li><p>build_preprocess_fn</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">build_preprocess_fn</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">use_preprocessor</span><span class="p">:</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="n">CommonPreprocessor</span><span class="p">(</span>
                    <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                    <span class="n">token_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">token_type</span><span class="p">,</span>
                    <span class="n">token_list</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">token_list</span><span class="p">,</span>
                    <span class="n">bpemodel</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">bpemodel</span><span class="p">,</span>
                    <span class="n">non_linguistic_symbols</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">non_linguistic_symbols</span><span class="p">,</span>
                    <span class="n">text_cleaner</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cleaner</span><span class="p">,</span>
                    <span class="o">...</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">retval</span>
</pre></div>
</div>
<p>This function defines how to preprocess samples. Specifically, the input of speech recognition tasks includes speech and text. For speech, functions such as (optional) adding noise and reverberation to the speech are supported. For text, functions such as (optional) processing text according to bpe and mapping text to <code class="docutils literal notranslate"><span class="pre">tokenid</span></code> are supported. Users can choose the preprocessing operation that needs to be performed on the sample. For the detail implementation, please refer to <code class="docutils literal notranslate"><span class="pre">CommonPreprocessor</span></code>.</p>
<ul class="simple">
<li><p>build_collate_fn</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">build_collate_fn</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">CommonCollateFn</span><span class="p">(</span><span class="n">float_pad_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">int_pad_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>This function defines how to combine multiple samples into a <code class="docutils literal notranslate"><span class="pre">batch</span></code>. For speech recognition tasks, <code class="docutils literal notranslate"><span class="pre">padding</span></code> is employed to obtain equal-length data from different speech and text. Specifically, we set <code class="docutils literal notranslate"><span class="pre">0.0</span></code> as the default padding value for speech and <code class="docutils literal notranslate"><span class="pre">-1</span></code> as the default padding value for text. Users can define different <code class="docutils literal notranslate"><span class="pre">batch</span></code> operations here. For the detail implementation, please refer to <code class="docutils literal notranslate"><span class="pre">CommonCollateFn</span></code>.</p>
<ul class="simple">
<li><p>build_model</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">token_list</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">token_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_list</span><span class="p">)</span>
        <span class="n">frontend</span> <span class="o">=</span> <span class="n">frontend_class</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">frontend_conf</span><span class="p">)</span>
        <span class="n">specaug</span> <span class="o">=</span> <span class="n">specaug_class</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">specaug_conf</span><span class="p">)</span>
        <span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize_class</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">normalize_conf</span><span class="p">)</span>
        <span class="n">preencoder</span> <span class="o">=</span> <span class="n">preencoder_class</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">preencoder_conf</span><span class="p">)</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder_class</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">encoder_conf</span><span class="p">)</span>
        <span class="n">postencoder</span> <span class="o">=</span> <span class="n">postencoder_class</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">encoder_output_size</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">postencoder_conf</span><span class="p">)</span>
        <span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder_class</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">encoder_output_size</span><span class="o">=</span><span class="n">encoder_output_size</span><span class="p">,</span>  <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">decoder_conf</span><span class="p">)</span>
        <span class="n">ctc</span> <span class="o">=</span> <span class="n">CTC</span><span class="p">(</span><span class="n">odim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">encoder_output_size</span><span class="o">=</span><span class="n">encoder_output_size</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">ctc_conf</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">frontend</span><span class="o">=</span><span class="n">frontend</span><span class="p">,</span>
            <span class="n">specaug</span><span class="o">=</span><span class="n">specaug</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
            <span class="n">preencoder</span><span class="o">=</span><span class="n">preencoder</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
            <span class="n">postencoder</span><span class="o">=</span><span class="n">postencoder</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">ctc</span><span class="o">=</span><span class="n">ctc</span><span class="p">,</span>
            <span class="n">token_list</span><span class="o">=</span><span class="n">token_list</span><span class="p">,</span>
            <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">model_conf</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>This function defines the detail of the model. For different speech recognition models, the same speech recognition <code class="docutils literal notranslate"><span class="pre">Task</span></code> can usually be shared and the remaining thing needed to be done is to define a specific model in this function. For example, a speech recognition model with a standard encoder-decoder structure has been shown above. Specifically, it first defines each module of the model, including encoder, decoder, etc. and then combine these modules together to generate a complete model. In FunASR, the model needs to inherit <code class="docutils literal notranslate"><span class="pre">AbsESPnetModel</span></code> and the corresponding code can be seen in <code class="docutils literal notranslate"><span class="pre">funasr/train/abs_espnet_model.py</span></code>. The main function needed to be implemented is the <code class="docutils literal notranslate"><span class="pre">forward</span></code> function.</p>
<p>Next, we take <code class="docutils literal notranslate"><span class="pre">SANMEncoder</span></code> as an example to introduce how to use a custom encoder as a part of the model when defining the specified model and the corresponding code can be seen in <code class="docutils literal notranslate"><span class="pre">funasr/models/encoder/sanm_encoder.py</span></code>. For a custom encoder, in addition to inheriting the common encoder class <code class="docutils literal notranslate"><span class="pre">AbsEncoder</span></code>, it is also necessary to define the <code class="docutils literal notranslate"><span class="pre">forward</span></code> function to achieve the forward computation of the <code class="docutils literal notranslate"><span class="pre">encoder</span></code>. After defining the <code class="docutils literal notranslate"><span class="pre">encoder</span></code>, it should also be registered in the <code class="docutils literal notranslate"><span class="pre">Task</span></code>. The corresponding code example can be seen as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder_choices</span> <span class="o">=</span> <span class="n">ClassChoices</span><span class="p">(</span>
    <span class="s2">&quot;encoder&quot;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">conformer</span><span class="o">=</span><span class="n">ConformerEncoder</span><span class="p">,</span>
        <span class="n">transformer</span><span class="o">=</span><span class="n">TransformerEncoder</span><span class="p">,</span>
        <span class="n">rnn</span><span class="o">=</span><span class="n">RNNEncoder</span><span class="p">,</span>
        <span class="n">sanm</span><span class="o">=</span><span class="n">SANMEncoder</span><span class="p">,</span>
        <span class="n">sanm_chunk_opt</span><span class="o">=</span><span class="n">SANMEncoderChunkOpt</span><span class="p">,</span>
        <span class="n">data2vec_encoder</span><span class="o">=</span><span class="n">Data2VecEncoder</span><span class="p">,</span>
        <span class="n">mfcca_enc</span><span class="o">=</span><span class="n">MFCCAEncoder</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">type_check</span><span class="o">=</span><span class="n">AbsEncoder</span><span class="p">,</span>
    <span class="n">default</span><span class="o">=</span><span class="s2">&quot;rnn&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In this code, <code class="docutils literal notranslate"><span class="pre">sanm=SANMEncoder</span></code> takes the newly defined <code class="docutils literal notranslate"><span class="pre">SANMEncoder</span></code> as an optional choice of the <code class="docutils literal notranslate"><span class="pre">encoder</span></code>. Once the user specifies the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> as <code class="docutils literal notranslate"><span class="pre">sanm</span></code> in the configuration file, the <code class="docutils literal notranslate"><span class="pre">SANMEncoder</span></code> will be correspondingly employed as the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> module of the model.</p>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modescope_pipeline/sd_pipeline.html" class="btn btn-neutral float-left" title="Speaker Diarization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="runtime/export.html" class="btn btn-neutral float-right" title="Export models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Speech Lab, Alibaba Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>